{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Access the key by its name\n",
        "mistral_api_key = userdata.get('Mistral_API')\n",
        "\n",
        "# Use the api_key variable in your API call\n",
        "if mistral_api_key is not None:\n",
        "    # Your API call code here\n",
        "    pass\n",
        "else:\n",
        "    print(\"API key not found in Colab secrets.\")"
      ],
      "metadata": {
        "id": "dMLpmjTrRDIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfzfBV5lqui3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def find_sum(x:int, y:int)->int:\n",
        "  \"\"\"This function is used to sum two numbers and return their product\n",
        "  It takes two integers as inputs and returns an integer as output\"\"\"\n",
        "  return x+y\n"
      ],
      "metadata": {
        "id": "XPTMhREFq3LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def find_product(x:int, y:int)->int:\n",
        "  \"\"\"This function is used to multiply two numbers and return their products\n",
        "  It takes two integers as inputs and return as integer as output\"\"\"\n",
        "  return x*y"
      ],
      "metadata": {
        "id": "AnRz6Sm5rUET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-mistralai"
      ],
      "metadata": {
        "id": "5QSAgRMisFcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "models = ChatMistralAI(\n",
        "    model=\"mistral-large-latest\",\n",
        "    temperature=0,\n",
        "    api_key=mistral_api_key\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "J6i4fQkusHxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage,HumanMessage, SystemMessage\n"
      ],
      "metadata": {
        "id": "GgPc1-Bwsbrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_tools = [find_sum,find_product]"
      ],
      "metadata": {
        "id": "OUNUVet4sbpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"You are a Math Genius who can solve math problems. Solve the problems provided by the user, by using only tools available, Do not solve the problem yourself\"\"\""
      ],
      "metadata": {
        "id": "1cXdPKVIsbmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent"
      ],
      "metadata": {
        "id": "27RvyRtOsbkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_agent(\n",
        "    model=models,\n",
        "    system_prompt=system_prompt,\n",
        "    tools = agent_tools\n",
        ")"
      ],
      "metadata": {
        "id": "85keG7MFsbhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\"messages\":[(\"user\",\"What is the sum of 2 and 3?\")]}\n",
        "result = agent.invoke(input)"
      ],
      "metadata": {
        "id": "uy0ATUCasbZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['messages'][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDtb0J6Zu6xQ",
        "outputId": "cca9df41-bc9f-43e3-ab07-7e51b648f9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of 2 and 3 is **5**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Step by Step Execution\")\n",
        "for message in result['messages']:\n",
        "  print(message.pretty_repr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgrQqfBau6sH",
        "outputId": "5fd9cbaf-e786-4cc9-c973-00edefff0a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step by Step Execution\n",
            "================================ Human Message =================================\n",
            "\n",
            "What is the sum of 2 and 3?\n",
            "================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  find_sum (r0leCynuo)\n",
            " Call ID: r0leCynuo\n",
            "  Args:\n",
            "    x: 2\n",
            "    y: 3\n",
            "================================= Tool Message =================================\n",
            "Name: find_sum\n",
            "\n",
            "5\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "The sum of 2 and 3 is **5**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = {\"messages\":[(\"user\",\"What is the 3 multiplied by 2 and 5+1\")]}\n",
        "result = agent.invoke(input)"
      ],
      "metadata": {
        "id": "EitwWW_Bu6p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['messages'][-1].content)\n",
        "print(\"Step by Step Execution\")\n",
        "for message in result['messages']:\n",
        "  print(message.pretty_repr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgTuUUulu6nK",
        "outputId": "9b56e3b9-c8a1-467b-eaa5-ea22e42cd458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The product of 3 multiplied by 2 is **6**.\n",
            "\n",
            "The sum of 5 and 1 is **6**.\n",
            "Step by Step Execution\n",
            "================================ Human Message =================================\n",
            "\n",
            "What is the 3 multiplied by 2 and 5+1\n",
            "================================== Ai Message ==================================\n",
            "Tool Calls:\n",
            "  find_product (PK4DoZsMb)\n",
            " Call ID: PK4DoZsMb\n",
            "  Args:\n",
            "    x: 3\n",
            "    y: 2\n",
            "  find_sum (dCA1HOvBJ)\n",
            " Call ID: dCA1HOvBJ\n",
            "  Args:\n",
            "    x: 5\n",
            "    y: 1\n",
            "================================= Tool Message =================================\n",
            "Name: find_product\n",
            "\n",
            "6\n",
            "================================= Tool Message =================================\n",
            "Name: find_sum\n",
            "\n",
            "6\n",
            "================================== Ai Message ==================================\n",
            "\n",
            "The product of 3 multiplied by 2 is **6**.\n",
            "\n",
            "The sum of 5 and 1 is **6**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import MistralAIEmbeddings\n",
        "embeddings = MistralAIEmbeddings(\n",
        "    model = \"mistral-embed\",\n",
        "    api_key=mistral_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "yqbcO670u6k5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d98fd33-c548-4c03-e679-be22221b2682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add product pricing function tool"
      ],
      "metadata": {
        "id": "vYZyatKazqZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain_core.tools import tool"
      ],
      "metadata": {
        "id": "Ew6S2l_4u6iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_pricing_df = pd.read_csv(\"/content/drive/MyDrive/Data_Sets/RAG_and_AgenticRAG/Laptop pricing.csv\")"
      ],
      "metadata": {
        "id": "zU3Mx-FFu6f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(product_pricing_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6n9sAjQu6db",
        "outputId": "8110981a-08f1-4e65-9190-0979619dd4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Name  Price  ShippingDays\n",
            "0  AlphaBook Pro   1499             2\n",
            "1     GammaAir X   1399             7\n",
            "2  SpectraBook S   2499             7\n",
            "3   OmegaPro G17   2199            14\n",
            "4  NanoEdge Flex   1699             2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_laptop_price(laptop_name : str)->int:\n",
        "  \"\"\"This function returns the price of the laptop, if you send it's name as input\"\"\"\n",
        "  matched_record_df = product_pricing_df[product_pricing_df['Name'].str.contains(\"^\"+laptop_name, case = False)]\n",
        "  if len(matched_record_df) == 0:\n",
        "    return -1\n",
        "  else:\n",
        "    return matched_record_df['Price'].iloc[0]\n"
      ],
      "metadata": {
        "id": "V4k8qp5Qu6bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain-chroma>=0.1.2\"\n",
        "!pip install langchain_community\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOzg2gWT28oS",
        "outputId": "882da429-8c82-4cbd-9d0f-03bf8eccf230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.2.5)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.41.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Collecting pypdf\n",
            "  Using cached pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Using cached pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-6.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "FCxSizi8u6Yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d845147c-7a93-480c-bae0-94fc52eb2f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Data_Sets/RAG_and_AgenticRAG/Laptop product descriptions.pdf\")"
      ],
      "metadata": {
        "id": "EOFoM3pbu6WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "YADuRmTlu6TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "PSAGaDQJu6Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a vector store with Chroma\n",
        "prod_feature_store = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "65g_OlAfu6NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = prod_feature_store.as_retriever()"
      ],
      "metadata": {
        "id": "gpO5ODWj4csB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_product_features(query: str) -> str:\n",
        "  \"\"\"Search and return information about given product\"\"\"\n",
        "  docs = retriever.invoke(query)\n",
        "  return \"\\n\\n\".join([doc.page_content for doc in docs])"
      ],
      "metadata": {
        "id": "LHtoo9HQ4cpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent"
      ],
      "metadata": {
        "id": "SaqkwLmb4cm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n"
      ],
      "metadata": {
        "id": "t0XrVLvY4ckH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = SystemMessage(\"\"\"\n",
        "    You are professional chatbot that answers questions about laptops sold by your company.\n",
        "    To answer questions about laptops, you will ONLY use the available tools and NOT your own memory.\n",
        "    You will handle small talk and greetings by producing professional responses.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "q2MJwLoV4chd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [get_laptop_price, get_product_features]"
      ],
      "metadata": {
        "id": "vu5KkaR14cey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer=MemorySaver()\n"
      ],
      "metadata": {
        "id": "FG09oXeW4ccA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Product QnA Agent. This is actual a graph in langGraph\n",
        "product_QnA_agent=create_agent(\n",
        "                                model=models, #LLM to use\n",
        "                                tools=tools, #List of tools to use\n",
        "                                system_prompt=system_prompt, #The system prompt\n",
        "                                debug=False, #Debugging turned on if needed\n",
        "                                checkpointer=checkpointer #For conversation memory\n",
        ")"
      ],
      "metadata": {
        "id": "6MrdpDh44cZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "#To maintain memory, each request should be in the context of a thread.\n",
        "#Each user conversation will use a separate thread ID\n",
        "config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
        "\n",
        "#Test the agent with an input\n",
        "inputs = {\"messages\":[\n",
        "                HumanMessage(\"What are the features and pricing for GammaAir?\")\n",
        "            ]}"
      ],
      "metadata": {
        "id": "vC78rHMt4cW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#This is an alternate way to stream agent responses without waiting for the agent to finish\n",
        "for stream in product_QnA_agent.stream(inputs, config, stream_mode=\"values\"):\n",
        "    message=stream[\"messages\"][-1]\n",
        "    if isinstance(message, tuple):\n",
        "        print(message)\n",
        "    else:\n",
        "        message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1KXpitI4cUR",
        "outputId": "e8fa385a-b23f-4659-f1df-5721422b1edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What are the features and pricing for GammaAir?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  get_laptop_price (rSmPJMBZW)\n",
            " Call ID: rSmPJMBZW\n",
            "  Args:\n",
            "    laptop_name: GammaAir\n",
            "  get_product_features (6167tv16K)\n",
            " Call ID: 6167tv16K\n",
            "  Args:\n",
            "    query: GammaAir\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: get_product_features\n",
            "\n",
            "OmegaPro G17\n",
            "OmegaPro G17 is a gaming powerhouse with a Ryzen 9 5900HX CPU, 32GB RAM, and a 1TB\n",
            "SSD. Designed for gamers, it features a 17-inch display with a high refresh rate and powerful\n",
            "graphics card for the best gaming experience.\n",
            "NanoEdge Flex\n",
            "NanoEdge Flex is a versatile 2-in-1 laptop with Apple's M1 Pro chip, 16GB of unified memory, and a\n",
            "512GB SSD. It's perfect for creative professionals who need a device that can transform between a\n",
            "laptop and a tablet.\n",
            "\n",
            "Fictional Laptop Descriptions\n",
            "AlphaBook Pro\n",
            "The AlphaBook Pro is a sleek ultrabook with a 12th Gen Intel i7 processor, 16GB of DDR4 RAM,\n",
            "and a fast 1TB SSD. Ideal for professionals on the go, this laptop offers an impressive blend of\n",
            "power and portability.\n",
            "GammaAir X\n",
            "GammaAir X combines an AMD Ryzen 7 processor with 32GB of DDR4 memory and a 512GB\n",
            "NVMe SSD. Its thin and light form factor makes it perfect for users who need high performance in a\n",
            "portable design.\n",
            "SpectraBook S\n",
            "Designed for power users, SpectraBook S features an Intel Core i9 processor, 64GB RAM, and a\n",
            "massive 2TB SSD. This workstation-class laptop is perfect for intensive tasks like video editing and\n",
            "3D rendering.\n",
            "OmegaPro G17\n",
            "OmegaPro G17 is a gaming powerhouse with a Ryzen 9 5900HX CPU, 32GB RAM, and a 1TB\n",
            "SSD. Designed for gamers, it features a 17-inch display with a high refresh rate and powerful\n",
            "graphics card for the best gaming experience.\n",
            "NanoEdge Flex\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The **GammaAir X** (assuming you meant this model based on the available data) is a high-performance laptop designed for users who need power and portability. Here are its features and pricing:\n",
            "\n",
            "### **Features:**\n",
            "- **Processor:** AMD Ryzen 7\n",
            "- **RAM:** 32GB DDR4\n",
            "- **Storage:** 512GB NVMe SSD\n",
            "- **Design:** Thin and light form factor, ideal for portability\n",
            "- **Use Case:** Great for high-performance tasks like multitasking, content creation, and light gaming.\n",
            "\n",
            "### **Price:**\n",
            "- **$1,399** (USD)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "#Send a sequence of messages to chatbot and get its response\n",
        "#This simulates the conversation between the user and the Agentic chatbot\n",
        "user_inputs = [\n",
        "    \"Hello\",\n",
        "    \"I am looking to buy a laptop\",\n",
        "    \"Give me a list of available laptop names\",\n",
        "    \"Tell me about the features of  SpectraBook\",\n",
        "    \"How much does it cost?\",\n",
        "    \"Give me similar information about OmegaPro\",\n",
        "    \"What info do you have on AcmeRight ?\",\n",
        "    \"Thanks for the help\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "r2q85iE94cR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new thread\n",
        "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "\n",
        "for input in user_inputs:\n",
        "    print(f\"----------------------------------------\\nUSER : {input}\")\n",
        "    #Format the user message\n",
        "    user_message = {\"messages\":[HumanMessage(input)]}\n",
        "    #Get response from the agent\n",
        "    ai_response = product_QnA_agent.invoke(user_message,config=config)\n",
        "    #Print the response\n",
        "    print(f\"AGENT : {ai_response['messages'][-1].content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43aFuE0x4cPQ",
        "outputId": "0917b4f1-69b4-4dfd-d403-0244adcb761a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "USER : Hello\n",
            "AGENT : Hello! How can I assist you today? Are you looking for information about any of our laptops?\n",
            "----------------------------------------\n",
            "USER : I am looking to buy a laptop\n",
            "AGENT : Great! We have a variety of laptops to suit different needsâ€”whether it's for work, gaming, study, or everyday use.\n",
            "\n",
            "Could you let me know what you're looking for in a laptop? For example:\n",
            "- **Budget range**\n",
            "- **Preferred brand or specifications** (e.g., RAM, storage, processor)\n",
            "- **Primary use** (e.g., gaming, programming, design, general use)\n",
            "- **Any specific features** (e.g., lightweight, touchscreen, long battery life)\n",
            "----------------------------------------\n",
            "USER : Give me a list of available laptop names\n",
            "AGENT : I currently don't have a direct list of all available laptop names, but I can help you find information about specific laptops if you let me know what you're interested in.\n",
            "\n",
            "For example, if you're looking for laptops like:\n",
            "- **Dell XPS 13**\n",
            "- **MacBook Pro**\n",
            "- **HP Spectre x360**\n",
            "- **Lenovo ThinkPad X1 Carbon**\n",
            "- **ASUS ROG Zephyrus (Gaming Laptop)**\n",
            "- **Acer Swift 3**\n",
            "----------------------------------------\n",
            "USER : Tell me about the features of  SpectraBook\n",
            "AGENT : Here are the features of the **SpectraBook S** (assuming you meant this model based on the available data):\n",
            "\n",
            "### **SpectraBook S Features**\n",
            "- **Processor**: Intel Core i9 (high-performance processor for demanding tasks)\n",
            "- **RAM**: 64GB (ideal for multitasking, heavy workloads, and professional applications)\n",
            "- **Storage**: 2TB SSD (fast and spacious storage for large files, applications, and projects)\n",
            "- **Use Case**: Designed for **power users**, such as video editors, 3D renderers, and professionals who need a **workstation-class laptop** for intensive tasks.\n",
            "\n",
            "If you were referring to a different **SpectraBook** model, let me know, and I can help further! Alternatively, if you meant the **HP Spectre x360**, I can look up its details as well.\n",
            "----------------------------------------\n",
            "USER : How much does it cost?\n",
            "AGENT : The **SpectraBook S** is priced at **$2,499**.\n",
            "\n",
            "Would you like assistance with anything else, such as comparisons with other models or additional features?\n",
            "----------------------------------------\n",
            "USER : Give me similar information about OmegaPro\n",
            "AGENT : Hereâ€™s the detailed information about the **OmegaPro G17** gaming laptop:\n",
            "\n",
            "### **OmegaPro G17 Features**\n",
            "- **Processor**: AMD Ryzen 9 5900HX (high-performance CPU for gaming and heavy tasks)\n",
            "- **RAM**: 32GB (great for multitasking and gaming)\n",
            "- **Storage**: 1TB SSD (fast storage for games, applications, and files)\n",
            "- **Display**: 17-inch with a **high refresh rate** (ideal for smooth gaming visuals)\n",
            "- **Graphics**: Powerful dedicated graphics card (for an immersive gaming experience)\n",
            "- **Use Case**: Designed for **gamers** and users who need high performance for demanding applications.\n",
            "\n",
            "### **Price**\n",
            "The **OmegaPro G17** costs **$2,199**.\n",
            "\n",
            "Would you like a comparison with other gaming laptops or more details?\n",
            "----------------------------------------\n",
            "USER : What info do you have on AcmeRight ?\n",
            "AGENT : It looks like I don't have any information available on the **AcmeRight** laptop in my current database.\n",
            "\n",
            "Could you confirm if you meant a different model or brand? Here are a few possibilities:\n",
            "- Did you mean **Acer** (e.g., Acer Swift, Acer Predator)?\n",
            "- Or perhaps another model like **AlphaBook Pro**, **GammaAir X**, or **NanoEdge Flex**?\n",
            "----------------------------------------\n",
            "USER : Thanks for the help\n",
            "AGENT : You're welcome! If you have any more questions in the futureâ€”whether about laptops or anything elseâ€”feel free to reach out. Have a great day! ðŸ˜Š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conversation memory by user\n",
        "def execute_prompt(user, config, prompt):\n",
        "    inputs = {\"messages\":[(\"user\",prompt)]}\n",
        "    ai_response = product_QnA_agent.invoke(inputs,config=config)\n",
        "    print(f\"\\n{user}: {ai_response['messages'][-1].content}\")\n",
        "\n",
        "#Create different session threads for 2 users\n",
        "config_1 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "config_2 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "\n",
        "#Test both threads\n",
        "execute_prompt(\"USER 1\", config_1, \"Tell me about the features of  SpectraBook\")\n",
        "execute_prompt(\"USER 2\", config_2, \"Tell me about the features of  GammaAir\")\n",
        "execute_prompt(\"USER 1\", config_1, \"What is its price ?\")\n",
        "execute_prompt(\"USER 2\", config_2, \"What is its price ?\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj6-O-jf4cMf",
        "outputId": "90210202-d16a-4b18-f876-3cba79e5cc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "USER 1: Here are the features of the **SpectraBook S**:\n",
            "\n",
            "- **Processor**: Intel Core i9 (workstation-class performance)\n",
            "- **RAM**: 64GB (ideal for intensive multitasking)\n",
            "- **Storage**: 2TB SSD (massive storage for large files and applications)\n",
            "- **Use Case**: Perfect for power users, video editing, 3D rendering, and other demanding tasks.\n",
            "\n",
            "USER 2: Here are the features of the **GammaAir X** laptop:\n",
            "\n",
            "- **Processor:** AMD Ryzen 7 (high-performance processing)\n",
            "- **RAM:** 32GB DDR4 (supports multitasking and smooth performance)\n",
            "- **Storage:** 512GB NVMe SSD (fast storage for quick boot and load times)\n",
            "- **Design:** Thin and light form factor (highly portable)\n",
            "- **Best For:** Users who need **high performance** in a **portable** design.\n",
            "\n",
            "Would you like to know its price or compare it with another laptop?\n",
            "\n",
            "USER 1: The **SpectraBook S** is priced at **$2,499**.\n",
            "\n",
            "USER 2: The **GammaAir X** is priced at **$1,399**.\n",
            "\n",
            "Would you like assistance with anything else, such as comparisons or availability?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OS7dVmAy4cJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L47jqDiK4cHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F42YHT7E4cEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u2XXNPw64cB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Bjub2rtwJ_m7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MbfdYb074b_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHLTcj8x4b85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bfdgCUy4b6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkI2E6LJ4b36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "esNN768-4b1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bjGJjryh4by8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMKOGxD04bwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ka1DpwtW4bt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "siIArN_z4brP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMIduNTP4box"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTA50cev4bmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJLOLERA4bjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zFnwBXCZsLUy"
      }
    }
  ]
}